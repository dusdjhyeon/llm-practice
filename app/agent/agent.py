import datetime

from langchain.agents import AgentExecutor, LLMSingleActionAgent, Tool
from langchain.cache import InMemoryCache
from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI
from langchain.globals import set_llm_cache

from app.agent.parser import CustomAgentOutputParser
from app.agent.prompts import AgentPromptTemplate, agent_prompt_template
from app.agent.tools import get_veg_name, get_veg_info
from app.core.config import settings

set_llm_cache(InMemoryCache())

class ExecutorAgent:
    """
    ExecutorAgent class represents an agent that executes queries using a set of tools.

    Attributes:
        llm (ChatOpenAI): The language model used for generating responses.
        tools (list[Tool]): The list of tools available for executing queries.
        agent_prompt (AgentPromptTemplate): The template for agent prompts.
        output_parser (CustomAgentOutputParser): The output parser for parsing agent responses.
        agent (LLMSingleActionAgent): The language model agent for executing queries.
        executor (AgentExecutor): The executor for running queries using the agent and tools.

    Methods:
        run(query): Executes a query using the executor and returns the response.
    """
    def __init__(self):

        self.llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=settings.OPENAI_API_KEY)
        self.tools = [ 
            Tool(
                name = "veg_info",
                func = get_veg_info,
                description = """만약 사용자가 작물을 어떻게 길러야 할지를 물어본다면 get_veg_info를 사용해서 답변해줘.""",
            ),
            Tool(
                name="veg_recom", 
                func= get_veg_name,
                description= "만약 사용자가 작물을 추천해달라고 하면 get_veg_name을 사용해서 답변을 해줘.",
            )
        ]
        
        self.agent_prompt = AgentPromptTemplate(
            template=agent_prompt_template,
            tools=self.tools,
            input_variables=["input", "intermediate_steps"],
        )

        self.output_parser = CustomAgentOutputParser()
        llm_chain = LLMChain(llm=self.llm, prompt=self.agent_prompt)
        tool_names = [tool.name for tool in self.tools]
        self.agent = LLMSingleActionAgent(
            llm_chain=llm_chain, output_parser=self.output_parser, allowed_tools = tool_names, verbose = False, stop=["\nObservation:"]
        )
        
        self.executor = AgentExecutor.from_agent_and_tools(
            agent = self.agent, verbose=True, max_iterations=5, tools = self.tools
        )

    def run(self, query):
        """
        Executes a query using the executor and returns the response.
        Args:
            query (str): The query to be executed.
        Returns:
            str: The response generated by the agent.
        """
        response = self.executor.run(query)
        return response
    